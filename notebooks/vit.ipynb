{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, AdamW\n",
    "import torch\n",
    "from torchmetrics import MetricCollection, MeanAbsoluteError, MeanSquaredError, ExplainedVariance\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_cosh_loss(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    def _log_cosh(x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + nn.functional.softplus(-2. * x) - math.log(2.0)\n",
    "    return torch.mean(_log_cosh(y_pred - y_true))\n",
    "\n",
    "class LogCoshLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_pred: Tensor, y_true: Tensor) -> torch.Tensor:\n",
    "        return log_cosh_loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAV_vit(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, backbone, learning_rate=1e-6, loss_threshold=0.5, weight_decay=1e-1, batch_size: int = 16, no_grad_layers_n: int = 6, dropout: float = 0.0, attention_dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = backbone\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_threshold = loss_threshold\n",
    "        self.weight_decay = weight_decay\n",
    "        # self.criterion = nn.HuberLoss(delta=loss_threshold)\n",
    "        # self.criterion = nn.SmoothL1Loss(beta=self.loss_threshold)\n",
    "        self.criterion = LogCoshLoss()\n",
    "        self.optimizer = AdamW(backbone.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        self.no_grad_layers_n = int(no_grad_layers_n)\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "        self.attention_dropout = attention_dropout\n",
    "\n",
    "        self.test_output = []\n",
    "        self.test_loss = []\n",
    "        self.test_targets_mean = []\n",
    "        # Set dropout\n",
    "        self.apply(lambda m: self.set_dropouts(m))\n",
    "\n",
    "        # Get the number of input features of the last layer of the backbone\n",
    "        num_input_filters = backbone.heads[0].in_features\n",
    "        num_output_values = 1\n",
    "\n",
    "        # Replace the head of the model\n",
    "        self.backbone.heads[0] = nn.Linear(in_features=num_input_filters, out_features=num_output_values).float()\n",
    "        \n",
    "        metric_collection = MetricCollection([\n",
    "            MeanSquaredError(),\n",
    "            MeanAbsoluteError(),\n",
    "            ExplainedVariance()\n",
    "        ])\n",
    "        self.val_metrics = metric_collection.clone(prefix=\"val_\")\n",
    "        self.test_metrics = metric_collection.clone(prefix=\"test_\")\n",
    "\n",
    "        if(self.no_grad_layers_n > 0):\n",
    "            for i, param in enumerate(self.backbone.encoder.parameters()):\n",
    "                if i < self.no_grad_layers_n:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def set_dropouts(self, m):\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.p = self.dropout\n",
    "        elif isinstance(m, nn.MultiheadAttention):\n",
    "            m.dropout = self.attention_dropout   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "    \n",
    "    def get_batch_data(self, batch):\n",
    "        images, labels = batch\n",
    "        labels = labels.unsqueeze(1)\n",
    "        outputs = self.forward(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        return outputs, labels, loss\n",
    "    \n",
    "    # Training\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, loss = self.get_batch_data(batch)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    # Validation\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self.get_batch_data(batch)\n",
    "        step_metrics = self.val_metrics.forward(outputs, labels)\n",
    "        self.log_dict(step_metrics, on_epoch=True, on_step=False)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    # Testing\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self.get_batch_data(batch)\n",
    "        step_metrics = self.test_metrics.forward(outputs, labels)\n",
    "\n",
    "        outputs = outputs.squeeze().cpu().numpy()\n",
    "        labels = labels.squeeze().cpu().numpy()\n",
    "\n",
    "        self.test_output.extend(outputs)\n",
    "        self.test_loss.append(loss.item())\n",
    "        self.test_targets_mean.append(np.mean(labels))\n",
    "\n",
    "        self.log_dict(step_metrics, on_epoch=True, on_step=False)\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, on_step=False)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    # Prediction\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        outputs = self(batch)\n",
    "        return outputs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
