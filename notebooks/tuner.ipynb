{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from ray import train, tune\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import RunConfig, ScalingConfig, CheckpointConfig\n",
    "from ray.train.lightning import (\n",
    "    RayDDPStrategy,\n",
    "    RayLightningEnvironment,\n",
    "    RayTrainReportCallback,\n",
    "    prepare_trainer,\n",
    ")\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torchvision.models import get_model, ViT_B_32_Weights, ViT_B_16_Weights\n",
    "from torch.optim import Adam, AdamW\n",
    "from torchmetrics import LogCoshError, MeanAbsoluteError, MeanSquaredError\n",
    "# import mlflow\n",
    "# from ray.air.integrations.mlflow import setup_mlflow\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torchmetrics import MetricCollection, MeanAbsoluteError, MeanSquaredError, ExplainedVariance\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Define model_config\n",
    "model_config = {\n",
    "    \"protected_namespaces\": ()\n",
    "}\n",
    "\n",
    "# Update model_config\n",
    "model_config['protected_namespaces'] = ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dataset.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from dataset import PlotsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"RAY_DEDUP_LOGS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DATASET_PATH = \"../data/raw/Case_Study_1/Raw_Images\"\n",
    "GCP_PATH = \"../data/GCP_Images\"\n",
    "GROUND_TRUTH_PATH = '../data/ground_truth/ground_truth.csv'\n",
    "MODEL_PATH = \"../data/models/\"\n",
    "CHECKPOINT_PATH = \"../data/checkpoints/\"\n",
    "ORTHOMOSAIC_PATH = \"../data/orthophoto/raster.tif\"\n",
    "PLOT_PATH = \"../data/plots\"\n",
    "SAMPLES_PATH = \"../data/raw_samples\"\n",
    "SHAPEFILE_PATH = \"../data/shapefile/all_plots.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "TEST_SIZE = 0.2 # % of dataset\n",
    "VAL_SIZE = 0.2  # % of training set\n",
    "\n",
    "MAX_EPOCS = -1\n",
    "BATCH_SIZE = 8\n",
    "WORKERS = 8\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "BACKBONE_NAME = \"vit_b_32\"\n",
    "BACKBONE_WEIGHTS = ViT_B_32_Weights.IMAGENET1K_V1\n",
    "PATIENCE = 30\n",
    "\n",
    "learning_rate = 1e-5\n",
    "FROZEN_LAYERS = 6\n",
    "WEIGHT_DECAY = 1e-3\n",
    "DROPOUT = 0.3\n",
    "ATTENTION_DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TunableVit(pl.LightningModule):\n",
    "    def __init__(self, backbone, criterion, optimizer, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.weight_decay = config[\"weight_decay\"]\n",
    "        self.no_grad_layers_n = config[\"no_grad_layers_n\"]\n",
    "        self.batch_size = config[\"batch_size\"]\n",
    "        self.dropout = config[\"dropout\"]\n",
    "        self.attention_dropout = config[\"attention_dropout\"]\n",
    "        self.backbone = backbone\n",
    "\n",
    "        self.test_output = []\n",
    "        self.test_loss = []\n",
    "        self.test_label_mean = []\n",
    "        if(self.no_grad_layers_n > 0):\n",
    "            for i, param in enumerate(self.backbone.encoder.parameters()):\n",
    "                if i < self.no_grad_layers_n:\n",
    "                    param.requires_grad = False\n",
    "        self.set_dropouts()\n",
    "\n",
    "        # Get the number of input features of the last layer of the backbone\n",
    "        num_input_filters = backbone.heads[0].in_features\n",
    "        num_output_values = 1\n",
    "\n",
    "        # Replace the head of the model\n",
    "        self.backbone.heads[0] = nn.Linear(in_features=num_input_filters, out_features=num_output_values).float()\n",
    "        \n",
    "        metric_collection = MetricCollection([\n",
    "            MeanSquaredError(),\n",
    "            MeanAbsoluteError(),\n",
    "            ExplainedVariance()\n",
    "        ])\n",
    "        self.val_metrics = metric_collection.clone(prefix=\"val_\")\n",
    "        self.test_metrics = metric_collection.clone(prefix=\"test_\")\n",
    "\n",
    "\n",
    "\n",
    "    def set_dropouts(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Dropout):\n",
    "                m.p = self.dropout\n",
    "            elif isinstance(m, nn.MultiheadAttention):\n",
    "                m.dropout = self.attention_dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "    \n",
    "    # Training\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, loss = self.get_batch_data(batch)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    # Validation\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self.get_batch_data(batch)\n",
    "        step_metrics = self.val_metrics.forward(outputs, labels)\n",
    "        self.log_dict(step_metrics, on_epoch=True, on_step=False)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    # Testing\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self.get_batch_data(batch)\n",
    "        step_metrics = self.test_metrics.forward(outputs, labels)\n",
    "\n",
    "        outputs = outputs.squeeze().cpu().numpy()\n",
    "        labels = labels.squeeze().cpu().numpy()\n",
    "\n",
    "        self.test_output.extend(outputs)\n",
    "        self.test_loss.append(loss.item())\n",
    "        self.test_label_mean.append(np.mean(labels))\n",
    "\n",
    "        self.log_dict(step_metrics, on_epoch=True, on_step=False)\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, on_step=False)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        outputs = self.forward(batch)\n",
    "        predictions = [x.item() for x in outputs.detach().cpu().numpy()]\n",
    "        return predictions\n",
    "    \n",
    "    def get_batch_data(self, batch):\n",
    "        images, labels = batch\n",
    "        labels = labels.unsqueeze(-1)\n",
    "        outputs = self.backbone(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        return outputs, labels, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ray config\n",
    "\n",
    "METRIC = \"val_loss\"\n",
    "MODE = \"min\"\n",
    "BACKBONE_NAME = \"vit_b_32\"\n",
    "BACKBONE_WEIGHTS = ViT_B_32_Weights.IMAGENET1K_V1\n",
    "NUM_EPOCHS = 5\n",
    "NUM_SAMPLES = 10\n",
    "SEARCH_SPACE = {\n",
    "    \"learning_rate\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"batch_size\": tune.choice([8, 16, 32]),\n",
    "    \"no_grad_layers_n\": tune.choice([0, 1, 2, 3, 4, 5]),\n",
    "    \"dropout\": tune.choice([0.0, 0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "    \"attention_dropout\": tune.choice([0.0, 0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "    \"experiment_name\": \"pl_tune_uav_vit\",\n",
    "    \"weight_decay\": tune.loguniform(1e-1, 1e-5),\n",
    "}\n",
    "use_gpu = False\n",
    "num_workers = 4\n",
    "resources_per_worker={\"CPU\": 1}\n",
    "\n",
    "default_config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 8,\n",
    "    \"no_grad_layers_n\": 0,\n",
    "    \"dropout\": 0.0,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"experiment_name\": \"pl_tune_uav_vit\",\n",
    "    \"weight_decay\": 1e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 451\n",
      "Validation set size: 113\n",
      "Test set size: 141\n",
      "Train Dataloader size: 57\n",
      "Validation Dataloader size: 15\n",
      "Test Dataloader size: 18\n"
     ]
    }
   ],
   "source": [
    "# Ground truth, dataset and dataloaders\n",
    "\n",
    "ground_truth = pd.read_csv(GROUND_TRUTH_PATH)\n",
    "\n",
    "# Elevation format conversion to float32\n",
    "ground_truth[\"elev\"] = ground_truth[\"elev\"].astype(\"float32\")\n",
    "labels_norm = ground_truth[\"elev\"]\n",
    "ground_truth.head()\n",
    "\n",
    "# Targets normalization\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ground_truth[\"elev\"] = scaler.fit_transform(ground_truth[[\"elev\"]])\n",
    "\n",
    "base_dataset = {\n",
    "    \"name\": \"base\",\n",
    "    \"dataset\": PlotsDataset(labels=ground_truth, img_dir=PLOT_PATH, img_size=IMG_SIZE, transforms=None),\n",
    "}\n",
    "dataset = base_dataset[\"dataset\"]\n",
    "\n",
    "# Dataset split\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, test_size=TEST_SIZE)\n",
    "train_set, val_set = train_test_split(train_set, test_size=VAL_SIZE)\n",
    "\n",
    "print(f\"Training set size: {len(train_set)}\")\n",
    "print(f\"Validation set size: {len(val_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")\n",
    "\n",
    "# Dataloaders\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=WORKERS)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=WORKERS)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=WORKERS)\n",
    "\n",
    "print(f\"Train Dataloader size: {len(train_loader)}\")\n",
    "print(f\"Validation Dataloader size: {len(val_loader)}\")\n",
    "print(f\"Test Dataloader size: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    # setup_mlflow(\n",
    "    #     config,\n",
    "    #     experiment_name=config.get(\"experiment_name\", None),\n",
    "    #     tracking_uri=config.get(\"tracking_uri\", None),\n",
    "    # )\n",
    "    criterion = LogCoshError()\n",
    "    backbone = get_model(BACKBONE_NAME, weights=BACKBONE_WEIGHTS)\n",
    "    optimizer = AdamW(backbone.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"])\n",
    "    model = TunableVit(backbone, criterion, optimizer, config)\n",
    "    \n",
    "    # mlflow.pytorch.autolog()\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        devices=\"auto\",\n",
    "        accelerator=\"auto\",\n",
    "        strategy=RayDDPStrategy(),\n",
    "        max_epochs=NUM_SAMPLES,\n",
    "        callbacks=[RayTrainReportCallback()],\n",
    "        plugins=[RayLightningEnvironment()],\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    trainer = prepare_trainer(trainer)\n",
    "    trainer.fit(model, train_loader)\n",
    "    # trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parallel workers\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=num_workers, use_gpu=use_gpu, resources_per_worker=resources_per_worker\n",
    ")\n",
    "\n",
    "# Ray trainer setup\n",
    "run_config = RunConfig(\n",
    "    checkpoint_config=CheckpointConfig(\n",
    "        num_to_keep=2,\n",
    "        checkpoint_score_attribute=METRIC,\n",
    "        checkpoint_score_order=MODE\n",
    "    ),\n",
    ")\n",
    "\n",
    "ray_trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vit_tuner(metric=METRIC, mode=MODE, num_samples=NUM_SAMPLES, experiment_name=\"pl_tuning\"):\n",
    "    scheduler = ASHAScheduler(max_t=NUM_EPOCHS, grace_period=1, reduction_factor=2)\n",
    "\n",
    "    # mlflow.set_experiment(experiment_name)\n",
    "    tuner = tune.Tuner(\n",
    "        ray_trainer,\n",
    "        param_space={\"train_loop_config\": SEARCH_SPACE},\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=metric,\n",
    "            mode=mode,\n",
    "            num_samples=num_samples,\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "    )\n",
    "    return tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-10-17 19:55:10</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:33.65        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.5/15.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 5.0/8 CPUs, 0/1 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">    train_loop_config/at\n",
       "tention_dropout</th><th style=\"text-align: right;\">   train_loop_config/ba\n",
       "tch_size</th><th style=\"text-align: right;\">    train_loop_config/dr\n",
       "opout</th><th style=\"text-align: right;\">            train_loop_config/le\n",
       "arning_rate</th><th style=\"text-align: right;\">  train_loop_config/no\n",
       "_grad_layers_n</th><th style=\"text-align: right;\">            train_loop_config/we\n",
       "ight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_d0dde_00000</td><td>RUNNING </td><td>127.0.0.1:7884</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">1.67824e-05</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.00247118 </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.3</td><td style=\"text-align: right;\"> 8</td><td style=\"text-align: right;\">0.4</td><td style=\"text-align: right;\">1.68149e-05</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.000143579</td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\"> 8</td><td style=\"text-align: right;\">0.1</td><td style=\"text-align: right;\">0.000303171</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.0490588  </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\">16</td><td style=\"text-align: right;\">0.5</td><td style=\"text-align: right;\">1.40841e-06</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">0.0974765  </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.3</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0.4</td><td style=\"text-align: right;\">3.87829e-06</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0.0346637  </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.4</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0.3</td><td style=\"text-align: right;\">0.000495205</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00560083 </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">0.000201238</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.0158583  </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0  </td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0.4</td><td style=\"text-align: right;\">0.00944795 </td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">0.00921454 </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00008</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.2</td><td style=\"text-align: right;\">16</td><td style=\"text-align: right;\">0.4</td><td style=\"text-align: right;\">0.000251012</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0.00365252 </td></tr>\n",
       "<tr><td>TorchTrainer_d0dde_00009</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.4</td><td style=\"text-align: right;\">32</td><td style=\"text-align: right;\">0.4</td><td style=\"text-align: right;\">0.00023094 </td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">0.0124522  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 19:51:36,941\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,946\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,952\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,958\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,963\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,970\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,975\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,980\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,987\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "2023-10-17 19:51:36,992\tINFO data_parallel_trainer.py:407 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m * 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m   warnings.warn(message, UserWarning)\n",
      "\u001b[2m\u001b[36m(TrainTrainable pid=7884)\u001b[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=7884)\u001b[0m GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=7884)\u001b[0m Starting distributed worker processes: ['2224 (127.0.0.1)', '5628 (127.0.0.1)', '568 (127.0.0.1)', '5660 (127.0.0.1)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m Setting up process group for: env:// [rank=0, world_size=4]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m [W ..\\torch\\csrc\\distributed\\c10d\\socket.cpp:601] [c10d] The client socket has failed to connect to [home.local]:55334 (system error: 10049 - Indirizzo richiesto non valido nel proprio contesto.).\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m [W ..\\torch\\csrc\\distributed\\c10d\\socket.cpp:601] [c10d] The client socket has failed to connect to [home.local]:55334 (system error: 10049 - Indirizzo richiesto non valido nel proprio contesto.).\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m * 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m   warnings.warn(message, UserWarning)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m [W ..\\torch\\csrc\\distributed\\c10d\\socket.cpp:601] [c10d] The client socket has failed to connect to [home.local]:55334 (system error: 10049 - Indirizzo richiesto non valido nel proprio contesto.).\u001b[32m [repeated 6x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m   warnings.warn(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:269: UserWarning: Valid config keys have changed in V2:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m * 'schema_extra' has been renamed to 'json_schema_extra'\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m   warnings.warn(message, UserWarning)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m Missing logger folder: C:\\Users\\Thuls\\ray_results\\TorchTrainer_2023-10-17_19-51-28\\TorchTrainer_d0dde_00000_0_attention_dropout=0.5000,batch_size=32,dropout=0.5000,learning_rate=0.0000,no_grad_layers_n=0,weight_de_2023-10-17_19-51-36\\lightning_logs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m   | Name         | Type              | Params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 0 | criterion    | LogCoshError      | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 1 | backbone     | VisionTransformer | 87.5 M\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 2 | val_metrics  | MetricCollection  | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 3 | test_metrics | MetricCollection  | 0     \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m ---------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 87.5 M    Trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 87.5 M    Total params\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m 349.824   Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:281: PossibleUserWarning: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5660)\u001b[0m Missing logger folder: C:\\Users\\Thuls\\ray_results\\TorchTrainer_2023-10-17_19-51-28\\TorchTrainer_d0dde_00000_0_attention_dropout=0.5000,batch_size=32,dropout=0.5000,learning_rate=0.0000,no_grad_layers_n=0,weight_de_2023-10-17_19-51-36\\lightning_logs\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m grad.sizes() = [1, 1, 768], strides() = [38400, 768, 1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m bucket_view.sizes() = [1, 1, 768], strides() = [768, 768, 1] (Triggered internally at ..\\torch\\csrc\\distributed\\c10d\\reducer.cpp:337.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:433: PossibleUserWarning: It is recommended to use `self.log('train_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=2224)\u001b[0m   warning_cache.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=C:/Users/Thuls/ray_results/TorchTrainer_2023-10-17_19-51-28/TorchTrainer_d0dde_00000_0_attention_dropout=0.5000,batch_size=32,dropout=0.5000,learning_rate=0.0000,no_grad_layers_n=0,weight_de_2023-10-17_19-51-36/checkpoint_000000)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m grad.sizes() = [1, 1, 768], strides() = [38400, 768, 1]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m bucket_view.sizes() = [1, 1, 768], strides() = [768, 768, 1] (Triggered internally at ..\\torch\\csrc\\distributed\\c10d\\reducer.cpp:337.)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(\"C:/Users/Thuls/ray_results/TorchTrainer_2023-10-17_19-51-28\", trainable=...)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1391\u001b[0m, in \u001b[0;36mTuneController._schedule_trial_task.<locals>._on_result\u001b[1;34m(tracked_actor, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1391\u001b[0m     on_result(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1392\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1704\u001b[0m, in \u001b[0;36mTuneController._on_training_result\u001b[1;34m(self, trial, result)\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[39mwith\u001b[39;00m warn_if_slow(\u001b[39m\"\u001b[39m\u001b[39mprocess_trial_result\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1704\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_trial_results(trial, result)\n\u001b[0;32m   1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_execute_queued_decision(trial, after_save\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1717\u001b[0m, in \u001b[0;36mTuneController._process_trial_results\u001b[1;34m(self, trial, results)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[39mwith\u001b[39;00m warn_if_slow(\u001b[39m\"\u001b[39m\u001b[39mprocess_trial_result\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1717\u001b[0m     decision \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_trial_result(trial, result)\n\u001b[0;32m   1718\u001b[0m \u001b[39mif\u001b[39;00m decision \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1719\u001b[0m     \u001b[39m# If we didn't get a decision, this means a\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[39m# non-training future (e.g. a save) was scheduled.\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[39m# We do not allow processing more results then.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1762\u001b[0m, in \u001b[0;36mTuneController._process_trial_result\u001b[1;34m(self, trial, result)\u001b[0m\n\u001b[0;32m   1761\u001b[0m flat_result \u001b[39m=\u001b[39m flatten_dict(result)\n\u001b[1;32m-> 1762\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_result_metrics(flat_result)\n\u001b[0;32m   1764\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stopper(trial\u001b[39m.\u001b[39mtrial_id, result) \u001b[39mor\u001b[39;00m trial\u001b[39m.\u001b[39mshould_stop(flat_result):\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1869\u001b[0m, in \u001b[0;36mTuneController._validate_result_metrics\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m   1868\u001b[0m \u001b[39mif\u001b[39;00m report_metric:\n\u001b[1;32m-> 1869\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1870\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrial returned a result which did not include the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1871\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspecified metric(s) `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m` that `\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m` expects. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1872\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMake sure your calls to `tune.report()` include the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1873\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmetric, or set the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1874\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTUNE_DISABLE_STRICT_METRIC_CHECKING \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1875\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39menvironment variable to 1. Result: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1876\u001b[0m             report_metric, location, result\n\u001b[0;32m   1877\u001b[0m         )\n\u001b[0;32m   1878\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Trial returned a result which did not include the specified metric(s) `val_loss` that `tune.TuneConfig()` expects. Make sure your calls to `tune.report()` include the metric, or set the TUNE_DISABLE_STRICT_METRIC_CHECKING environment variable to 1. Result: {'train_loss': 0.10257411003112793, 'epoch': 0, 'step': 15, 'timestamp': 1697565310, 'should_checkpoint': True, 'done': False, 'training_iteration': 1, 'trial_id': 'd0dde_00000', 'date': '2023-10-17_19-55-10', 'time_this_iter_s': 207.43117904663086, 'time_total_s': 207.43117904663086, 'pid': 7884, 'hostname': 'Cube', 'node_ip': '127.0.0.1', 'time_since_restore': 207.43117904663086, 'iterations_since_restore': 1, 'checkpoint_dir_name': 'checkpoint_000000', 'config/train_loop_config/learning_rate': 1.6782381194187892e-05, 'config/train_loop_config/batch_size': 32, 'config/train_loop_config/no_grad_layers_n': 0, 'config/train_loop_config/dropout': 0.5, 'config/train_loop_config/attention_dropout': 0.5, 'config/train_loop_config/experiment_name': 'pl_tune_uav_vit', 'config/train_loop_config/weight_decay': 0.0024711788660717656}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\tuner.py:372\u001b[0m, in \u001b[0;36mTuner.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 372\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_local_tuner\u001b[39m.\u001b[39;49mfit()\n\u001b[0;32m    373\u001b[0m \u001b[39mexcept\u001b[39;00m TuneError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\impl\\tuner_internal.py:579\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_restored:\n\u001b[1;32m--> 579\u001b[0m     analysis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_internal(trainable, param_space)\n\u001b[0;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\impl\\tuner_internal.py:699\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[1;34m(self, trainable, param_space)\u001b[0m\n\u001b[0;32m    687\u001b[0m args \u001b[39m=\u001b[39m {\n\u001b[0;32m    688\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[0;32m    689\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tuner_kwargs,\n\u001b[0;32m    698\u001b[0m }\n\u001b[1;32m--> 699\u001b[0m analysis \u001b[39m=\u001b[39m run(\n\u001b[0;32m    700\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs,\n\u001b[0;32m    701\u001b[0m )\n\u001b[0;32m    702\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclear_remote_string_queue()\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\tune.py:1103\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _experiment_checkpoint_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[39mwhile\u001b[39;00m (\n\u001b[0;32m   1101\u001b[0m     \u001b[39mnot\u001b[39;00m runner\u001b[39m.\u001b[39mis_finished() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m experiment_interrupted_event\u001b[39m.\u001b[39mis_set()\n\u001b[0;32m   1102\u001b[0m ):\n\u001b[1;32m-> 1103\u001b[0m     runner\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m   1104\u001b[0m     \u001b[39mif\u001b[39;00m has_verbosity(Verbosity\u001b[39m.\u001b[39mV1_EXPERIMENT):\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:850\u001b[0m, in \u001b[0;36mTuneController.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[39m# Handle one event\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_actor_manager\u001b[39m.\u001b[39;49mnext(timeout\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m):\n\u001b[0;32m    851\u001b[0m     \u001b[39m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[0;32m    852\u001b[0m     \u001b[39m# insufficient resources\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_actor_manager\u001b[39m.\u001b[39mnum_live_actors:\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\air\\execution\\_internal\\actor_manager.py:224\u001b[0m, in \u001b[0;36mRayActorManager.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39melif\u001b[39;00m future \u001b[39min\u001b[39;00m actor_task_futures:\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_actor_task_events\u001b[39m.\u001b[39;49mresolve_future(future)\n\u001b[0;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py:118\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m on_result:\n\u001b[1;32m--> 118\u001b[0m     on_result(result)\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\air\\execution\\_internal\\actor_manager.py:765\u001b[0m, in \u001b[0;36mRayActorManager._schedule_tracked_actor_task.<locals>.on_result\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_result\u001b[39m(result: Any):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_actor_task_resolved(\n\u001b[0;32m    766\u001b[0m         tracked_actor_task\u001b[39m=\u001b[39;49mtracked_actor_task, result\u001b[39m=\u001b[39;49mresult\n\u001b[0;32m    767\u001b[0m     )\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\air\\execution\\_internal\\actor_manager.py:300\u001b[0m, in \u001b[0;36mRayActorManager._actor_task_resolved\u001b[1;34m(self, tracked_actor_task, result)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mif\u001b[39;00m tracked_actor_task\u001b[39m.\u001b[39m_on_result:\n\u001b[1;32m--> 300\u001b[0m     tracked_actor_task\u001b[39m.\u001b[39;49m_on_result(tracked_actor, result)\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1400\u001b[0m, in \u001b[0;36mTuneController._schedule_trial_task.<locals>._on_result\u001b[1;34m(tracked_actor, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1400\u001b[0m     \u001b[39mraise\u001b[39;00m TuneError(traceback\u001b[39m.\u001b[39mformat_exc())\n",
      "\u001b[1;31mTuneError\u001b[0m: Traceback (most recent call last):\n  File \"d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py\", line 1391, in _on_result\n    on_result(trial, *args, **kwargs)\n  File \"d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py\", line 1704, in _on_training_result\n    self._process_trial_results(trial, result)\n  File \"d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py\", line 1717, in _process_trial_results\n    decision = self._process_trial_result(trial, result)\n  File \"d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py\", line 1762, in _process_trial_result\n    self._validate_result_metrics(flat_result)\n  File \"d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\execution\\tune_controller.py\", line 1869, in _validate_result_metrics\n    raise ValueError(\nValueError: Trial returned a result which did not include the specified metric(s) `val_loss` that `tune.TuneConfig()` expects. Make sure your calls to `tune.report()` include the metric, or set the TUNE_DISABLE_STRICT_METRIC_CHECKING environment variable to 1. Result: {'train_loss': 0.10257411003112793, 'epoch': 0, 'step': 15, 'timestamp': 1697565310, 'should_checkpoint': True, 'done': False, 'training_iteration': 1, 'trial_id': 'd0dde_00000', 'date': '2023-10-17_19-55-10', 'time_this_iter_s': 207.43117904663086, 'time_total_s': 207.43117904663086, 'pid': 7884, 'hostname': 'Cube', 'node_ip': '127.0.0.1', 'time_since_restore': 207.43117904663086, 'iterations_since_restore': 1, 'checkpoint_dir_name': 'checkpoint_000000', 'config/train_loop_config/learning_rate': 1.6782381194187892e-05, 'config/train_loop_config/batch_size': 32, 'config/train_loop_config/no_grad_layers_n': 0, 'config/train_loop_config/dropout': 0.5, 'config/train_loop_config/attention_dropout': 0.5, 'config/train_loop_config/experiment_name': 'pl_tune_uav_vit', 'config/train_loop_config/weight_decay': 0.0024711788660717656}\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Repository\\UAV_ViT\\notebooks\\tuner.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m vit_tuner()\n",
      "\u001b[1;32md:\\Repository\\UAV_ViT\\notebooks\\tuner.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# mlflow.set_experiment(experiment_name)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tuner \u001b[39m=\u001b[39m tune\u001b[39m.\u001b[39mTuner(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     ray_trainer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     param_space\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mtrain_loop_config\u001b[39m\u001b[39m\"\u001b[39m: SEARCH_SPACE},\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     ),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Repository/UAV_ViT/notebooks/tuner.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tuner\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[1;32md:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\ray\\tune\\tuner.py:374\u001b[0m, in \u001b[0;36mTuner.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_tuner\u001b[39m.\u001b[39mfit()\n\u001b[0;32m    373\u001b[0m     \u001b[39mexcept\u001b[39;00m TuneError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 374\u001b[0m         \u001b[39mraise\u001b[39;00m TuneError(\n\u001b[0;32m    375\u001b[0m             _TUNER_FAILED_MSG\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    376\u001b[0m                 path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_tuner\u001b[39m.\u001b[39mget_experiment_checkpoint_dir()\n\u001b[0;32m    377\u001b[0m             )\n\u001b[0;32m    378\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     experiment_checkpoint_dir \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39mget(\n\u001b[0;32m    381\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remote_tuner\u001b[39m.\u001b[39mget_experiment_checkpoint_dir\u001b[39m.\u001b[39mremote()\n\u001b[0;32m    382\u001b[0m     )\n",
      "\u001b[1;31mTuneError\u001b[0m: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(\"C:/Users/Thuls/ray_results/TorchTrainer_2023-10-17_19-51-28\", trainable=...)`."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m   File \"<string>\", line 1, in <module>\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m   File \"C:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m     exitcode = _main(fd, parent_sentinel)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m   File \"C:\\Program Files\\Python310\\lib\\multiprocessing\\spawn.py\", line 126, in _main\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m     self = reduction.pickle.load(from_parent)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=5628)\u001b[0m EOFError: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "results = vit_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.get_best_result(metric=\"val_loss\", mode=\"min\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
