{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:127: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\Repository\\UAV_ViT\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class UAV_vit(pl.LightningModule):\n",
    "    def __init__(self, backbone, loss_fn, labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss_fn = loss_fn\n",
    "        self.model = backbone\n",
    "\n",
    "        # Dictionary { 'train': [], 'val': [], 'test': [] }\n",
    "        self.labels = labels\n",
    "\n",
    "        # Get the number of input features of the last layer of the backbone\n",
    "        num_input_filters = backbone.heads[0].in_features\n",
    "        num_output_values = 1\n",
    "\n",
    "        # Replace the head of the model\n",
    "        self.model.heads = nn.Linear(in_features=num_input_filters, out_features=num_output_values).float()\n",
    "\n",
    "        self.training_outputs = []\n",
    "        self.validation_outputs = []\n",
    "        self.testing_outputs = []\n",
    "\n",
    "        self.losses = {'train': [], 'val': [], 'test': []}\n",
    "        self.r2_scores = {'train': [], 'val': [], 'test': []}\n",
    "        self.maes = {'train': [], 'val': [], 'test': []}\n",
    "        self.rmses = {'train': [], 'val': [], 'test': []}\n",
    "        self.residuals = {'train': [], 'val': [], 'test': []}\n",
    "        self.predicted_values = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "        # List of dictionaries { 'loss': [], 'r2': [], 'mae': [], 'rmse': [] }\n",
    "        self.epoch_metrics = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    # Hooks     \n",
    "\n",
    "    # Training\n",
    "\n",
    "    def on_phase_start(self):\n",
    "        print(f\"\\n{self.phase} on_phase_start (labels {len(self.labels[self.phase])}): \")\n",
    "\n",
    "    def on_phase_step(self):\n",
    "        print(f\"{self.phase} on_phase_step: \")\n",
    "    \n",
    "    def on_phase_end(self):\n",
    "        print(f\"{self.phase} on_phase_end: \")\n",
    "\n",
    "    def on_fit_end(self) -> None:\n",
    "        print(f\" {self.phase} on_fit_end: \")\n",
    "\n",
    "    # Training\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self.phase = \"train\"\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self.get_batch_data(batch)\n",
    "        self.training_outputs.append(outputs)\n",
    "        r2, mae, rmse = self.get_metrics(outputs, labels)\n",
    "        self.log_step_metrics(batch_idx, outputs, labels, {\"loss\": loss, \"r2\": r2, \"mae\": mae, \"rmse\": rmse})\n",
    "        return loss\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    def on_validation_start(self):\n",
    "        self.phase = \"val\"\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self.get_batch_data(batch)\n",
    "        self.validation_outputs.append(outputs)\n",
    "        r2, mae, rmse = self.get_metrics(outputs, labels)\n",
    "        self.log_step_metrics(batch_idx, outputs, labels, {\"loss\": loss, \"r2\": r2, \"mae\": mae, \"rmse\": rmse})\n",
    "\n",
    "    # Testing\n",
    "\n",
    "    def on_test_start(self):\n",
    "        self.phase = \"test\"\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        outputs, labels, loss = self.get_batch_data(batch)\n",
    "        self.testing_outputs.append(outputs)\n",
    "        r2, mae, rmse = self.get_metrics(outputs, labels)\n",
    "        self.log_step_metrics(batch_idx, outputs, labels, {\"loss\": loss, \"r2\": r2, \"mae\": mae, \"rmse\": rmse})\n",
    "\n",
    "    # Helper functions\n",
    "\n",
    "    def get_batch_data(self, batch):\n",
    "        images, labels = batch\n",
    "        labels = labels.view(-1, 1)\n",
    "        outputs = self.model(images)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "\n",
    "        return outputs, labels, loss\n",
    "\n",
    "    def clear_metrics(self):\n",
    "        self.losses[self.phase] = []\n",
    "        self.rmses[self.phase] = []\n",
    "        self.r2_scores[self.phase] = []\n",
    "        self.maes[self.phase] = []\n",
    "        self.residuals[self.phase] = []\n",
    "        self.predicted_values[self.phase] = []\n",
    "  \n",
    "    def get_metrics(self, outputs, labels):\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "\n",
    "        r2 = r2_score(labels, outputs)\n",
    "        mae = mean_absolute_error(labels, outputs)\n",
    "        rmse = mean_squared_error(labels, outputs, squared=False)\n",
    "        return r2, mae, rmse\n",
    "\n",
    "    # Logging\n",
    "\n",
    "    def log_step_metrics(self, batch_idx, outputs, labels, metrics):\n",
    "        # Flatten the lists of single items' lists\n",
    "        residuals = [x.item() for residuals_sublist in (labels - outputs) for x in residuals_sublist]\n",
    "        predicted_values = [x.item() for predicted_sublist in outputs for x in predicted_sublist]\n",
    "\n",
    "        # batch_size values for each step\n",
    "        self.residuals[self.phase].append(residuals)\n",
    "        self.predicted_values[self.phase].append(predicted_values)\n",
    "\n",
    "        loss = metrics[\"loss\"].item()\n",
    "\n",
    "        # single value for each step\n",
    "\n",
    "        self.losses[self.phase].append(loss)\n",
    "        self.r2_scores[self.phase].append(metrics[\"r2\"])\n",
    "        self.maes[self.phase].append(metrics[\"mae\"])\n",
    "        self.rmses[self.phase].append(metrics[\"rmse\"])\n",
    "\n",
    "        self.log(\"loss\", loss, on_epoch=True, logger=True)\n",
    "        self.log(\"r2\", metrics[\"r2\"], on_epoch=True, logger=True)\n",
    "        self.log(\"mae\", metrics[\"mae\"], on_epoch=True, logger=True)\n",
    "        self.log(\"rmse\", metrics[\"rmse\"], on_epoch=True, logger=True)\n",
    "\n",
    "    def log_epoch_results(self) -> None:\n",
    "        # print(f\"{self.phase} log_epoch_results\")\n",
    "        \n",
    "        epoch_losses = [x[\"loss\"] for x in self.epoch_metrics]\n",
    "        epoch_r2 = [x[\"r2\"] for x in self.epoch_metrics]\n",
    "        epoch_mae = [x[\"mae\"] for x in self.epoch_metrics]\n",
    "        epoch_rmse = [x[\"rmse\"] for x in self.epoch_metrics]\n",
    "\n",
    "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        avg_r2 = sum(epoch_r2) / len(epoch_r2)\n",
    "        avg_mae = sum(epoch_mae) / len(epoch_mae)\n",
    "        avg_rmse = sum(epoch_rmse) / len(epoch_rmse)\n",
    "\n",
    "        mlflow.log_metric(f\"{self.phase}_loss\", avg_loss, step=self.current_epoch)\n",
    "        mlflow.log_metric(f\"{self.phase}_r2\", avg_mae, step=self.current_epoch)\n",
    "        mlflow.log_metric(f\"{self.phase}_mae\", avg_rmse, step=self.current_epoch)\n",
    "        mlflow.log_metric(f\"{self.phase}_rmse\", avg_r2, step=self.current_epoch)\n",
    "\n",
    "        self.epoch_metrics = []\n",
    "\n",
    "    # Visualization\n",
    "\n",
    "    def create_scatterplots(self):\n",
    "\n",
    "        losses = [x for losses_sublist in self.losses[self.phase] for x in losses_sublist]\n",
    "\n",
    "        print(f\"losses\", losses)\n",
    "        print(f\"r2 scores\", self.r2_scores[self.phase])\n",
    "\n",
    "        plt.scatter(self.losses[self.phase], self.r2_scores[self.phase], label=self.phase, alpha=0.5)\n",
    "        plt.xlabel('Loss')\n",
    "        plt.ylabel('R^2')\n",
    "        plt.title(f'{self.phase}: Scatter Plot: Loss vs R^2')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_residual_distribution(self):\n",
    "        plt.hist(self.residuals[self.phase])\n",
    "        plt.title(f'{self.phase}: Distribution of Residuals')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
