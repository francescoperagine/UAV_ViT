\section{Conclusion}
\label{sec:conclusion}

This study presents an innovative approach to crop yield prediction by leveraging deep learning techniques to forecast crop yield based on digital surface model (DSM) imagery of the field. We adopted a Vision Transformer (ViT) model, a transformer-based architecture that has exhibited strong performance in various computer vision tasks. Furthermore, our investigation involved the application of diverse loss functions, encompassing Huber Loss, Pseudo-Huber Loss, and the specially implemented Log-Cosh Loss, all aimed at optimizing the model's performance. The inclusion of informative visualizations greatly facilitated the assessment of the model's behavior and predictive capabilities.

Intriguingly, the outcomes reveal that the model, while showing promise, did not achieve a satisfactory R2Score. This suboptimal performance is attributed to a combination of factors. The misalignment between the ground truth data and the dataset, along with the constraints of a relatively small dataset, likely played a significant role. It is important to note that training a model with 86 million parameters with limited data may not be sufficient for robust performance.

Looking ahead, there are promising avenues for refinement. Scaling up the dataset size, adopting an alternative model architecture, and conducting a more comprehensive hyperparameter tuning process are all viable approaches. These steps hold the potential to harness the capabilities of the PyTorch ViT\_B\_32 model and advance its performance and resilience in the domain of crop yield prediction. 