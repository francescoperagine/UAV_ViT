{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## University of Bari Aldo Moro\n",
    "<a name=\"top\"></a>\n",
    "Master Degree in <b>Computer Science</b> - <b>Computer Vision Course</b><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Transformer for Unmanned Aerial Vehicles Agronomic Research\n",
    "- [Dependencies](#dependencies)\n",
    "- [Paths](#paths)\n",
    "- [Parameters](#parameters)\n",
    "- [Preprocessing](#preprocessing)\n",
    "    - [Ground Truth](#ground-truth)\n",
    "    - [GCP Finder](#gcp_finder)\n",
    "    - [Plots Clipper](#plots_clipper)\n",
    "- [Dataset](#dataset)\n",
    "- [Model](#model)\n",
    "    - [Training](#training)\n",
    "    - [Evaluation](#evaluation)\n",
    "    - [Inference](#inference)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "<a name='dependencies'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateFinder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import get_model, ViT_B_32_Weights, ViT_B_16_Weights, ViT_L_16_Weights, ViT_H_14_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.pytorch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from notebooks\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "from notebooks.gcp_finder import GCPFinder\n",
    "from notebooks.clipper import Clipper\n",
    "from notebooks.dataset import BaseDataset, PlotsDataset\n",
    "from notebooks.vit import UAV_vit\n",
    "from notebooks.visualization import Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuda setup\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and being used\", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths\n",
    "<a name=\"paths\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DATASET_PATH = \"./data/dataset\"\n",
    "PLOT_PATH = \"./data/plots\"\n",
    "SAMPLES_PATH = \"./data/raw_samples\"\n",
    "VISUALS_PATH = \"./data/visuals\"\n",
    "SHAPEFILE_PATH = \"./data/shapefile/all_plots.shp\"\n",
    "ORTHOMOSAIC_PATH = \"./data/orthomosaic/raster.tif\"\n",
    "GCP_PATH = \"./data/GCP_Images\"\n",
    "GROUND_TRUTH_PATH = './data/ground_truth/corn_plant_height_ground_truth.xlsx'\n",
    "MODEL_PATH = \"./data/models/\"\n",
    "CHECKPOINT_PATH = \"./data/checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "<a name='parameters'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "TEST_SIZE = 0.2 # % of dataset\n",
    "VAL_SIZE = 0.2  # % of training set\n",
    "\n",
    "MAX_EPOCS = -1\n",
    "BATCH_SIZE = 8\n",
    "WORKERS = 8\n",
    "IMG_SIZE = (224,224)\n",
    "\n",
    "BACKBONES = [\n",
    "    {'name': \"vit_b_16\", 'weights': ViT_B_16_Weights.DEFAULT}, # default ImageNet on DeIT recipe\n",
    "    {'name': \"vit_b_16\", 'weights': ViT_B_16_Weights.IMAGENET1K_SWAG_LINEAR_V1},\n",
    "    {'name': \"vit_b_32\", 'weights': ViT_B_32_Weights.DEFAULT},\n",
    "    {'name': \"vit_l_16\", 'weights': ViT_L_16_Weights.DEFAULT}, # recipe https://github.com/pytorch/vision/tree/main/references/classification#vit_l_16\n",
    "    {'name': \"vit_l_16\", 'weights': ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1},\n",
    "    {'name': \"vit_l_32\", 'weights': ViT_L_16_Weights.DEFAULT},\n",
    "    {'name': \"vit_h_14\", 'weights': ViT_H_14_Weights.IMAGENET1K_SWAG_LINEAR_V1},\n",
    "]\n",
    "BACKBONE = BACKBONES[4]\n",
    "\n",
    "FROZEN_LAYERS = 9\n",
    "\n",
    "ES_PATIENCE = 10\n",
    "ES_STOPPING_THRESHOLD = 1e-5\n",
    "ES_DIVERGENCE_THRESHOLD = 5\n",
    "\n",
    "LR_FINDER = True\n",
    "LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 1e-3\n",
    "DROPOUT = 0.3\n",
    "ATTENTION_DROPOUT = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "<a name='preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground truth\n",
    "<a name=\"ground_truth\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the ground truth\n",
    "df = pd.read_excel(GROUND_TRUTH_PATH)\n",
    "df[['DataFile 3', 'PHT(m)', 'Elev maximum (m)']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Preprocessing\n",
    "\n",
    "def renaming(filename):\n",
    "    return filename[:-4] + \".png\"\n",
    "\n",
    "def elev_avg(row):\n",
    "    return (row['PHT(m)'] + row[\"Elev maximum (m)\"]) / 2\n",
    "\n",
    "# Apply renaming and averaging\n",
    "df[\"filename\"] = df[\"DataFile 3\"].apply(renaming)\n",
    "df[\"elevation_avg\"] = (df.apply(elev_avg, axis=1))\n",
    "\n",
    "# Elevation format conversion to float32\n",
    "df[\"elevation_avg\"] = df[\"elevation_avg\"].astype(np.float32)\n",
    "df[['filename', 'elevation_avg']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets normalization\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[\"elevation\"] = scaler.fit_transform(df[[\"elevation_avg\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled targets\n",
    "\n",
    "df[[\"filename\", \"elevation\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Control Point (GCP) Finder\n",
    "<a name='gcp_finder'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcp_finder = GCPFinder(DATASET_PATH, GCP_PATH)\n",
    "# gcp_finder.gcp_mover()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots Clipper\n",
    "<a name='plots_clipper'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clipper = Clipper(ORTHOMOSAIC_PATH, SHAPEFILE_PATH, PLOT_PATH)\n",
    "# clipper.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "<a name=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets definition\n",
    "\n",
    "dataset = PlotsDataset(labels=df[[\"filename\", \"elevation\"]], img_dir=PLOT_PATH, img_size=IMG_SIZE)\n",
    "\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Image type: {type(dataset[0][0])}\")\n",
    "print(f\"Image shape: {dataset[0][0].shape})\")\n",
    "print(f\"Label type: {type(dataset[0][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset samples\n",
    "\n",
    "dataset.show_samples(df['elevation'], \"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel distribution\n",
    "\n",
    "plt.hist(dataset[0][0].permute(1,2,0).ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"Pixel values\")\n",
    "plt.ylabel(\"Relative frequency\")\n",
    "plt.title(\"Distribution of pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets means and stds\n",
    "\n",
    "means, stds = dataset.get_means_stds()\n",
    "print(f'Dataset means: {means}\\nstds: {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, test_size=TEST_SIZE)\n",
    "train_set, val_set = train_test_split(train_set, test_size=VAL_SIZE)\n",
    "\n",
    "print(f\"Training set size: {len(train_set)}\")\n",
    "print(f\"Validation set size: {len(val_set)}\")\n",
    "print(f\"Test set size: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=WORKERS)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=WORKERS)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=WORKERS)\n",
    "\n",
    "print(f\"Train Dataloader size: {len(train_loader)}\")\n",
    "print(f\"Validation Dataloader size: {len(val_loader)}\")\n",
    "print(f\"Test Dataloader size: {len(test_loader)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "<a name='model'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backbone\n",
    "\n",
    "backbone = get_model(BACKBONE['name'], weights=BACKBONE['weights'])\n",
    "backbone.heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vargs setup\n",
    "\n",
    "def setup_vargs(lr = LEARNING_RATE):\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--learning_rate', type=float, default=lr)\n",
    "    parser.add_argument('--weight_decay', type=float, default=WEIGHT_DECAY)\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE)\n",
    "    parser.add_argument('--no_grad_layers_n', type=int, default=FROZEN_LAYERS)\n",
    "    parser.add_argument('--dropout', type=float, default=DROPOUT)\n",
    "    parser.add_argument('--attention_dropout', type=float, default=ATTENTION_DROPOUT)\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    vargs = vars(args)\n",
    "    return vargs\n",
    "\n",
    "vargs = setup_vargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model = UAV_vit(backbone, **vargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backbone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "<a name='training'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow init\n",
    "\n",
    "mlflow.pytorch.autolog() \n",
    "mlflow.start_run()\n",
    "\n",
    "run = mlflow.active_run()\n",
    "log_run_id = run.info.run_id\n",
    "print(f\"Active run_id: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "\n",
    "learning_rate_finder_cb = LearningRateFinder()\n",
    "checkpoint_cb = ModelCheckpoint(dirpath=CHECKPOINT_PATH, save_top_k=1, monitor=\"val_loss\", mode=\"min\", filename=\"uav_vit-{epoch:02d}-{val_loss:.3f}\")\n",
    "earlyStopping_cb = EarlyStopping(monitor=\"val_loss\", patience=ES_PATIENCE, stopping_threshold=ES_STOPPING_THRESHOLD, divergence_threshold=ES_DIVERGENCE_THRESHOLD, mode=\"min\")\n",
    "\n",
    "callbacks = [earlyStopping_cb, checkpoint_cb]\n",
    "if LR_FINDER:\n",
    "    callbacks.append(learning_rate_finder_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCS,\n",
    "    callbacks=callbacks,\n",
    "    num_sanity_val_steps=0,\n",
    "    enable_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_FOUND = True if 'suggested_lr' in globals() else False\n",
    "if LR_FOUND:\n",
    "    suggested_lr = learning_rate_finder_cb.optimal_lr.suggestion()\n",
    "    learning_rate_finder_cb.optimal_lr.plot(suggest=True, show=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "<a name='testing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model path\n",
    "\n",
    "checkpoint_cb.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "\n",
    "vargs = setup_vargs(suggested_lr) if LR_FOUND else setup_vargs()\n",
    "model = UAV_vit.load_from_checkpoint(checkpoint_cb.best_model_path, backbone=backbone, **vargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test best model\n",
    "\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test results\n",
    "\n",
    "outputs = model.test_output\n",
    "test_loss = model.test_loss\n",
    "test_targets_mean = model.test_targets_mean\n",
    "test_targets = [x[1] for x in test_set]\n",
    "\n",
    "residuals = []\n",
    "for lab, out in zip(test_targets, outputs):\n",
    "    residuals.append(lab - out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 score\n",
    "\n",
    "r2 = r2_score(test_targets, outputs)\n",
    "print(f\"R2 score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "<a name='inference'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuals = Visualization(VISUALS_PATH, log_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuals.plot_residuals(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuals.plot_residuals_vs_outputs(residuals, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuals.plot_residuals_errors(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuals.plot_targets_means_vs_losses(test_targets_mean, test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visuals.plot_outputs_vs_targets(outputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log parameters\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"model\": BACKBONE['name'],\n",
    "    \"weights\": BACKBONE['weights'],\n",
    "    \"R2Score\": r2,\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"train_epochs\": MAX_EPOCS,\n",
    "    \"run_id\": log_run_id,\n",
    "    \"path\": checkpoint_cb.best_model_path,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"dropout_attention\": ATTENTION_DROPOUT,\n",
    "    \"frozen layers\": FROZEN_LAYERS\n",
    "    })\n",
    "if LR_FOUND:\n",
    "    mlflow.log_param(\"suggested_lr\", suggested_lr)\n",
    "\n",
    "mlflow.log_artifact(\"main.ipynb\")\n",
    "mlflow.log_artifact(\"notebooks/vit.ipynb\")\n",
    "mlflow.log_artifact(\"notebooks/dataset.ipynb\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesDataset = BaseDataset(SAMPLES_PATH, IMG_SIZE)\n",
    "samplesDataloader = DataLoader(samplesDataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = trainer.predict(model, dataloaders=samplesDataloader, return_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.concatenate(predictions)\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1,1))\n",
    "predictions = [item.item() for sublist in predictions for item in sublist]\n",
    "print(f\"Predicted results {predictions}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
